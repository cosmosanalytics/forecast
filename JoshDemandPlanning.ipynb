{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-py37",
      "display_name": "Python (env py37)",
      "language": "python"
    },
    "creator": "zhaoyang.wan@suez.com",
    "createdOn": 1672966652781,
    "tags": [],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.7.15",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "zhaoyang.wan@suez.com"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 3 input files\n# -- Test_Forecast_5_Mil_List_v2 for josh\n# -- TrueProductionData for production\n# -- All_Shipments_1 for shipment"
      ],
      "outputs": []
    },
    {
      "execution_count": 1,
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          32,
          79,
          95,
          104,
          117,
          144
        ]
      },
      "source": [
        "# common parameter\nstart \u003d \u00272021-01-01\u0027\ninitial \u003d \u0027540 days\u0027\n# ##############from 2019 to 2022 first half, \n### 3.5 year \u003d 1260 days, \n### from 2020, 2.5 year \u003d 900 days, \n### from 2021, 1.5 year \u003d 540 days \n\n# josh list \nimport dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd\nfrom prophet import Prophet\nfrom prophet.diagnostics import cross_validation\nfrom prophet.diagnostics import performance_metrics\nfrom prophet.utilities import regressor_coefficients\nfrom prophet.plot import plot_forecast_component\nimport json\nfrom prophet.serialize import model_to_json, model_from_json\n\n# from dask.distributed import Client\n# client \u003d Client()\n\nimport warnings\nwarnings.filterwarnings(\u0027ignore\u0027)\nimport logging\nlogging.getLogger(\u0027prophet\u0027).setLevel(logging.ERROR)\nlogger \u003d logging.getLogger(\u0027cmdstanpy\u0027)\nlogger.addHandler(logging.NullHandler())\nlogger.propagate \u003d False\nlogger.setLevel(logging.CRITICAL)\n\ndef load_data(flag):\n    if flag \u003d\u003d \u0027p\u0027:\n        df \u003d dataiku.Dataset(\"TrueProductionData\").get_dataframe().rename(columns\u003d{\u0027Material_Group_Id_Mara_Matkl\u0027:\u0027Generic\u0027})\n        df \u003d df[df[\u0027Plant\u0027].isin([3803, 3809, 3811, 3833, 3835, 3841])]\n        df[\u0027Date\u0027] \u003d pd.to_datetime(df[\u0027Date\u0027]) \n        df \u003d df[df[\u0027Date\u0027]\u003e\u003dpd.to_datetime(start)]\n        df[\u0027Year\u0027] \u003d df[\u0027Date\u0027].dt.year\n        df[\u0027Month\u0027] \u003d df[\u0027Date\u0027].dt.month\n        df \u003d df.groupby([\u0027Plant\u0027,\u0027Generic\u0027,\u0027Year\u0027,\u0027Month\u0027])[[\u0027KG\u0027]].sum().reset_index()\n        df[\u0027ds\u0027] \u003d pd.to_datetime(df[\u0027Year\u0027].astype(str)+\u0027-\u0027+df[\u0027Month\u0027].astype(str)+\u0027-1\u0027)  \n        df \u003d df[df[\u0027ds\u0027]\u003c\u003dpd.to_datetime(\u00272022-11-01\u0027)]\n    else:\n        All_Shipments_1 \u003d dataiku.Dataset(\"All_Shipments_1\")\n        All_Shipments_1_df \u003d All_Shipments_1.get_dataframe()\n        ship \u003d All_Shipments_1_df.copy()\n        df \u003d ship[ship[\u0027In/External Shipments\u0027]\u003d\u003d\u0027External SO\u0027][ship[\u0027Pole\u0027]\u003d\u003d\u0027NAM\u0027]\\\n            .groupby([\u0027Actual GI Date\u0027,\u0027Plant\u0027,\u0027Generic\u0027])[[\u0027KG\u0027]].sum().reset_index() \n        df \u003d df[df[\u0027Plant\u0027].isin([3803, 3809, 3811, 3833, 3835, 3841])]\n        df \u003d df.rename(columns\u003d{\u0027Actual GI Date\u0027:\u0027Date\u0027})\n        df[\u0027Date\u0027] \u003d pd.to_datetime(df[\u0027Date\u0027]) \n        df \u003d df[df[\u0027Date\u0027]\u003e\u003dpd.to_datetime(start)]\n        df[\u0027Year\u0027] \u003d df[\u0027Date\u0027].dt.year\n        df[\u0027Month\u0027] \u003d df[\u0027Date\u0027].dt.month\n        df \u003d df.groupby([\u0027Plant\u0027,\u0027Generic\u0027,\u0027Year\u0027,\u0027Month\u0027])[[\u0027KG\u0027]].sum().reset_index()\n        df[\u0027ds\u0027] \u003d pd.to_datetime(df[\u0027Year\u0027].astype(str)+\u0027-\u0027+df[\u0027Month\u0027].astype(str)+\u0027-1\u0027)  \n        df \u003d df[df[\u0027ds\u0027]\u003c\u003dpd.to_datetime(\u00272022-11-01\u0027)]         \n  \n    j \u003d dataiku.Dataset(\"Test_Forecast_5_Mil_List_v2\")\n    j_df \u003d j.get_dataframe()\n    gp \u003d pd.DataFrame(columns\u003d[\u0027Generic\u0027,\u0027Plant\u0027,\u0027KG\u0027])\n    gp[\u0027Generic\u0027] \u003d j_df[\u0027Generic-Plant\u0027].apply(lambda x: x.split(\u0027-\u0027)[0])\n    gp[\u0027Plant\u0027] \u003d j_df[\u0027Generic-Plant\u0027].apply(lambda x: x.split(\u0027-\u0027)[1])\n    gp[\u0027KG\u0027] \u003d gp\\\n    .apply(lambda x: df[df[\u0027Plant\u0027].astype(str)\u003d\u003dstr(x[\u0027Plant\u0027])][df[\u0027Generic\u0027].astype(str)\u003d\u003dstr(x[\u0027Generic\u0027])][\u0027KG\u0027].sum(), axis\u003d1)    \n    gp \u003d gp.sort_values(by\u003d\u0027KG\u0027, ascending\u003dFalse)\n \n    GDPC1_df \u003d dataiku.Dataset(\"GDPC1\").get_dataframe()\n    GDP_df \u003d dataiku.Dataset(\"GDP\").get_dataframe()  \n    GDPC1_df[\u0027col_0\u0027] \u003d pd.to_datetime(GDPC1_df[\u0027col_0\u0027])\n    GDPC1_df \u003d GDPC1_df.set_index(\u0027col_0\u0027)\n    GDPC1_df \u003d GDPC1_df.resample(\u0027MS\u0027).ffill()\n\n    GDP_df[\u0027col_0\u0027] \u003d pd.to_datetime(GDP_df[\u0027col_0\u0027])\n    GDP_df \u003d GDP_df.set_index(\u0027col_0\u0027)\n    GDP_df \u003d GDP_df.resample(\u0027MS\u0027).ffill()\n    return GDPC1_df, GDP_df, gp, df \n\ndef output_f(df1):\n    mode \u003d \u0027additive\u0027\n    m1 \u003d Prophet(seasonality_mode\u003dmode, daily_seasonality\u003dFalse, weekly_seasonality\u003dFalse, yearly_seasonality\u003d5);\n    m1 \u003d m1.add_seasonality(name\u003d\u0027quarterly\u0027, period\u003d365.24/4, fourier_order\u003d5)\n    m1.add_regressor(name\u003d\u0027Inflation\u0027,\n                      prior_scale\u003d10,\n                      standardize\u003d\u0027auto\u0027,\n                      mode\u003dmode)\n    m1.add_regressor(name\u003d\u0027GDPC1\u0027,\n                      prior_scale\u003d10,\n                      standardize\u003d\u0027auto\u0027,\n                      mode\u003dmode)\n    m1.fit(df1)\n    forecast \u003d m1.predict()\n    return forecast[[\u0027ds\u0027,\u0027yhat\u0027]], m1\n\ndef performance_f(m1):\n    df1_cv \u003d cross_validation(m1,\n                          horizon\u003d\u002730 days\u0027, #\n                          period\u003d\u002730 days\u0027, #\n                          initial\u003dinitial, #  \n                          parallel\u003d\"processes\")#parallel\u003d\u0027dask\u0027)\n    df1_p \u003d performance_metrics(df1_cv)\n    return df1_p\n\ndef input_f(GDPC1_df, GDP_df, df, p,m):\n    df \u003d df[df[\u0027Plant\u0027].astype(str)\u003d\u003dstr(p)][df[\u0027Generic\u0027].astype(str)\u003d\u003dstr(m)]\n    df \u003d df.drop(columns\u003d[\u0027Year\u0027,\u0027Month\u0027,\u0027Plant\u0027,\u0027Generic\u0027]).rename(columns\u003d{\u0027KG\u0027:\u0027y\u0027})\n    df \u003d df.groupby(\u0027ds\u0027)[\u0027y\u0027].sum().reset_index()\n    df1 \u003d df.set_index(\u0027ds\u0027) #\n    df1_ \u003d pd.DataFrame(index \u003d pd.DatetimeIndex(pd.date_range(start\u003dstart, end\u003d\u00272022-09-01\u0027, freq\u003d\"MS\"))) #####\n    df1 \u003d df1_.join(df1).fillna(0) #\n    df1 \u003d df1.join(GDP_df).join(GDPC1_df).reset_index().rename(columns\u003d{\u0027index\u0027:\u0027ds\u0027})\n    df1[\u0027ds\u0027] \u003d pd.to_datetime(df1[\u0027ds\u0027].astype(str))\n    df1[\u0027Inflation\u0027] \u003d 1-df1[\u0027GDPC1\u0027]/df1[\u0027GDP\u0027] \n    df1 \u003d df1.ffill()\n    return df1\n\ndef run_josh_list(GDPC1_df, GDP_df, df, lst):\n    ct\u003d0\n    output_df \u003d pd.DataFrame()\n    failedLst \u003d pd.DataFrame(columns\u003d[\u0027Plant\u0027, \u0027Generic\u0027])\n    perf_s \u003d pd.Series()\n    model_s \u003d pd.Series() \n    for p,m in zip(lst[\u0027Plant\u0027],lst[\u0027Generic\u0027]):\n        print(ct); ct\u003dct+1 \n        try:\n            df1 \u003d input_f(GDPC1_df, GDP_df, df, p,m)\n            fst, m1 \u003d output_f(df1)\n            model_s[str(p)+\u0027_\u0027+str(m)] \u003d model_to_json(m1) \n            \n            df1_p \u003d performance_f(m1)\n            tmp \u003d df1.set_index(\u0027ds\u0027)[[\u0027y\u0027]].join(fst.set_index(\u0027ds\u0027))\n            y_label \u003d str(p)+\u0027-\u0027+str(m)+\u0027_actual\u0027\n            yhat_label \u003d str(p)+\u0027-\u0027+str(m)+\u0027_model (corr. coef\u003d\u0027+str(tmp[\u0027y\u0027].corr(tmp[\u0027yhat\u0027]).round(3))+\u0027)\u0027\n            tmp \u003d tmp.rename(columns\u003d{\u0027y\u0027: y_label, \u0027yhat\u0027: yhat_label})  \n            output_df \u003d output_df.join(tmp, how\u003d\u0027right\u0027)\n            str1 \u003d str(df1_p[\u0027smape\u0027].median().round(3))\n            str2 \u003d str(tmp[y_label].corr(tmp[yhat_label]).round(3))\n            perf_s \u003d perf_s.append(pd.Series([str1+\u0027_\u0027+str2],index\u003d[str(p)+\u0027-\u0027+str(m)]))\n        except:\n            print(\u0027failed\u0027)\n            failedLst.loc[ct] \u003d [p, m]\n    return output_df, perf_s, model_s, failedLst \n\ndef p_or_s(flag):\n    GDPC1_df, GDP_df, gp, df \u003d load_data(flag)\n    print(len(gp[gp[\u0027KG\u0027]\u003d\u003d0]), len(gp))\n\n    n1, n2 \u003d 0,600\n    lst \u003d gp.iloc[n1:n2].copy()\n    output_df, perf_s, model_s, failedLst \u003d run_josh_list(GDPC1_df, GDP_df, df, lst) \n\n    Josh \u003d dataiku.Dataset(\u0027Josh_\u0027+flag)\n    Josh.write_with_schema(output_df.reset_index())\n\n    Perf \u003d dataiku.Dataset(\u0027Josh_\u0027+flag+\u0027_perf\u0027)\n    Perf.write_with_schema(pd.DataFrame({\u0027corr. coef\u0027: perf_s}).reset_index())\n\n    saveModel \u003d dataiku.Dataset(\u0027Josh_\u0027+flag+\u0027_saveModel\u0027) \n    saveModel.write_with_schema(pd.DataFrame({\u0027model\u0027: model_s}).reset_index()) \n\n    dataiku.Dataset(\u0027Josh_\u0027+flag+\u0027_failedList\u0027).write_with_schema(failedLst)\n    \n    df \u003d dataiku.Dataset(\"Josh_\"+flag).get_dataframe().set_index(\u0027ds\u0027)\n    dg \u003d df.stack().reset_index(level\u003d[\u0027ds\u0027, None])\n    dg[\u0027Index\u0027] \u003d dg[\u0027ds\u0027].astype(str).apply(lambda x: x.split(\u0027 \u0027)[0]) + \u0027_\u0027 + dg[\u0027level_1\u0027]\n    dg[\u0027Index\u0027] \u003d dg[\u0027Index\u0027].apply(lambda x: x.replace(\u0027_\u0027,\u0027 \u0027).split(\u0027 \u0027)[:3])\n    dg[\u0027Plant-Generic\u0027] \u003d dg[\u0027Index\u0027].apply(lambda x: x[1])\n    dg[\u0027Date\u0027] \u003d dg[\u0027Index\u0027].apply(lambda x: x[0])\n    dg[\u0027Actual or Model\u0027] \u003d dg[\u0027Index\u0027].apply(lambda x: x[2])\n    dg \u003d dg.drop(columns\u003d[\u0027ds\u0027, \u0027level_1\u0027, \u0027Index\u0027]).set_index([\u0027Plant-Generic\u0027, \u0027Actual or Model\u0027, \u0027Date\u0027])[0]\\\n        .unstack().unstack().dropna(axis\u003d1)\n    dg.columns \u003d [\u0027_\u0027.join(col) for col in dg.columns.values]\n    Dataset \u003d dataiku.Dataset(\u0027Josh_\u0027+flag+\u0027_Output\u0027) \n    Dataset.write_with_schema(dg.reset_index()) "
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p_or_s(\u0027p\u0027)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p_or_s(\u0027s\u0027)   "
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}